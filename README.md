# Mathematics of Machine Learning official code repository

Hi there! This is the official repository of the [Mathematics of Machine Learning](https://www.packtpub.com/en-us/product/mathematics-of-machine-learning-9781837027873) book.

## Getting started

You can run these Jupyter notebooks on remotely on cloud platforms like Google Colab, or locally on your machine. If you decide to run them virtually, you should create a virtual environment first:

```
virtualenv .venv
```

After the enviromnment is created, activate it and install the required Python packages.

```
source .venv/bin/activate
pip install -r requirements.txt
```

## Table of contents

### Part 1. Linear algebra

**Chapter 1. Vectors and vector spaces**

1.1. What is a vector space?  
1.2. The basis  
1.3. Vectors in practice  

**Chapter 2. The geometric structure of vector spaces**

2.1. Norms and distances  
2.2. Inner products, angles, and lots of reasons to care about them  

**Chapter 3. Linear algebra in practice**

3.1. Vectors in NumPy  
3.2. Matrices, the workhorses of linear algebra  

**Chapter 4. Linear transformations**

4.1. What is a linear transformation?  
4.2. Change of basis  
4.3. Linear transformations in the Euclidean plane  
4.4. Determinants, or how linear transformations affect volume  

**Chapter 5. Matrices and equations**

5.1. Linear equations  
5.2. The LU decomposition  
5.3. Determinants in practice  

**Chapter 7. Matrix factorizations**

7.1. Special transformations  
7.2. Self-adjoint transformations and the spectral decomposition theorem  
7.3. The Singular Value Decomposition  
7.4. Orthogonal projections  
7.5. Computing eigenvalues  
7.6. The QR algorithm  

**Chapter 8. Matrices and graphs**

8.1. The directed graph of a nonnegative matrix  
8.2. Benefits of the graph representation  
8.3. The Frobenius normal form  

### Part 2. Functions

**Chapter 9. Functions**

9.1. Functions in theory  
9.2. Functions in practice  

**Chapter 10. Numbers, sequences, and series**

10.1. Numbers  
10.2. Sequences  
10.3. Series  

**Chapter 11. Topology, limits, and continuity**

11.1. Topology  
11.2. Limits  
11.3. Continuity  

**Chapter 12. Differentiation**

12.1. Differentiation in theory  
12.2. Differentiation in practice  

**Chapter 13. Optimization**

13.1. Minima, maxima, and derivatives  
13.2. The basics of gradient descent  
13.3. Why does gradient descent work?  

**Chapter 14. Integration**

14.1. Integration in theory  
14.2. Integration in practice  

### Part 3. Multivariable functions

**Chapter 15. Multivariable functions**

15.1. What is a multivariable function?  
15.2. Linear functions in multiple variables  
15.3. The curse of dimensionality  

**Chapter 16. Derivatives and gradients**

16.1. Partial and total derivatives  
16.2. Derivatives of vector-valued functions  

**Chapter 17. Optimization in multiple variables**

17.1. Multivariable functions in code  
17.2. Minima and maxima, revisited  
17.3. Gradient descent in its full form  

### Part 4. Probability theory

**Chapter 18. What is probability?**

18.1. The language of thinking  
18.2. The axioms of probability  
18.3. Conditional probability  

**Chapter 19. Random variables and distributions**

19.1. Random variables  
19.2. Discrete distributions  
19.3. Real-valued distributions  
19.4. Density functions  

**Chapter 20. The expected value**

20.1. Discrete random variables  
20.2. Continuous random variables  
20.3. Properties of the expected value  
20.4. Variance  
20.5. The Law of Large Numbers  
20.6. Information theory  
20.7. The Maximum Likelihood Estimation  

